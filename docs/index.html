---

title: Wildlife Camera Trap Classifier

keywords: fastai
sidebar: home_sidebar

summary: "Computer Vision"
description: "Computer Vision"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This section of notebooks document the making of a computer vision pipeline created to automatically ingest photos (jpegs) collected from camera traps and sort them into useful classes defined by the user.</p>
<ul>
<li><strong>Why?</strong></li>
</ul>
<p>Camera traps offer vital information about an ecosystem for wildlife management. The manual sorting of hundreds of thousands of images however, is a labor intensive process and puts a constraint on the amount of information that can be extracted in a reasonable amount of time. If there were a way to automatically sort images with algorithms, more could be captured and more information could be extracted.</p>
<ul>
<li><strong>How?</strong></li>
</ul>
<p>The code here in written in Python and is built off the of the Pytorch library using Fastai <a href="https://course.fast.ai/part2">(course v3)</a> as a guide. We're using deep convolutional neural networks (CNNs) for our model architecture.</p>
<ul>
<li><strong>Warning</strong></li>
</ul>
<p>This documentation lays out the project but does not include the actual data or trained models. Hopefully, this implementation offers a practical guide and will be reusable on other species of animals / datasets with similar characteristics (i.e. camera traps).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Photos-/-Data">Photos / Data<a class="anchor-link" href="#Photos-/-Data"> </a></h3><p>Our data comes from camera traps that were setup in September of 2019 on a private ranch in South Texas. These camera traps have a night mode and a day mode and were set to take a 3 photo burst everything time motion was detected.</p>
<p>In total our dataset consisted of around 56,000 photos.</p>
<p>They look something like this...</p>
<p><img src="/wctc/images/IMG_0019s.JPG" alt=""></p>
<p>This photo is a full color day shot.</p>
<p>The camera traps are set up over feeding bins to document the Whitetail deer coming to feed.</p>
<p><img src="/wctc/images/IMG_0083s.JPG" alt=""></p>
<p>This is a grayscale night shot.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Inference-Pipeline">Inference Pipeline<a class="anchor-link" href="#Inference-Pipeline"> </a></h3><p>v1.0 relies on a chain of binary classifiers to sort the images into useful categories.</p>
<p>Each classifier examines each image passed to it and makes a predication as to whether the image is of class 1 or class 2.</p>
<p>In the final stage, when we have winnowed down the images, we will apply an Object Detection model to make one final classification.</p>
<ol>
<li>Chain of binary CNN classifiers</li>
<li>Object Detection CNN</li>
</ol>
<p>The downside of this technique is that though we are removing images as we get further downstream some images will have multiple predictions - and this is computationally inefficient. Later versions may experiment with different techniques like multi-label or multi-class.</p>
<p>The chain of binary classifiers is illustrated below:</p>
<p><img src="/wctc/images/deervision.png" alt=""></p>

</div>
</div>
</div>
    {% endraw %}
</div>
 

